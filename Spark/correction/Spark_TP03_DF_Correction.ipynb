{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use case with SPARK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start your HDFS cluster :"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "docker start namenode datanode1 datanode2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start your Spark cluster :"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "docker start smaster sworker1 sworker2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check all the following containers are up :\n",
    "\n",
    "smaster, sworker1, sworker2 \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "docker ps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This practice is based on a dataset from data.gouv.fr which you uploaded into hdfs while you studied HDFS.\n",
    "\n",
    "If you don't, please run the following cell :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-03-24 21:24:06--  https://files.data.gouv.fr/geo-dvf/latest/csv/2021/full.csv.gz\n",
      "Resolving files.data.gouv.fr (files.data.gouv.fr)... 51.38.54.240\n",
      "Connecting to files.data.gouv.fr (files.data.gouv.fr)|51.38.54.240|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 34657631 (33M) [application/octet-stream]\n",
      "Saving to: ‘/dataspark/2021-mutations-immobilieres.csv.gz’\n",
      "\n",
      "/dataspark/2021-mut 100%[===================>]  33.05M  41.8MB/s    in 0.8s    \n",
      "\n",
      "2022-03-24 21:24:07 (41.8 MB/s) - ‘/dataspark/2021-mutations-immobilieres.csv.gz’ saved [34657631/34657631]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!$HADOOP_HOME/bin/hdfs dfs -mkdir /data/permanent/rawdata/trade/\n",
    "!$HADOOP_HOME/bin/hdfs dfs -put /home/jovyan/data/2021-mutations-immobilieres.csv /data/permanent/rawdata/trade/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset represents all France real estate transfer in 2021."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the description of each column : \n",
    "\n",
    "```\n",
    "id_mutation : Identifiant de mutation (non stable, sert à grouper les lignes)\n",
    "date_mutation : Date de la mutation au format ISO-8601 (YYYY-MM-DD)\n",
    "numero_disposition : Numéro de disposition\n",
    "nature_mutation : Nature de la mutation\n",
    "valeur_fonciere : Valeur foncière (séparateur décimal = point)\n",
    "adresse_numero : Numéro de l'adresse\n",
    "adresse_suffixe : Suffixe du numéro de l'adresse (B, T, Q)\n",
    "adresse_code_voie : Code FANTOIR de la voie (4 caractères)\n",
    "adresse_nom_voie : Nom de la voie de l'adresse\n",
    "code_postal : Code postal (5 caractères)\n",
    "code_commune : Code commune INSEE (5 caractères)\n",
    "nom_commune : Nom de la commune (accentué)\n",
    "ancien_code_commune : Ancien code commune INSEE (si différent lors de la mutation)\n",
    "ancien_nom_commune : Ancien nom de la commune (si différent lors de la mutation)\n",
    "code_departement : Code département INSEE (2 ou 3 caractères)\n",
    "id_parcelle : Identifiant de parcelle (14 caractères)\n",
    "ancien_id_parcelle : Ancien identifiant de parcelle (si différent lors de la mutation)\n",
    "numero_volume : Numéro de volume\n",
    "lot_1_numero : Numéro du lot 1\n",
    "lot_1_surface_carrez : Surface Carrez du lot 1\n",
    "lot_2_numero : Numéro du lot 2\n",
    "lot_2_surface_carrez : Surface Carrez du lot 2\n",
    "lot_3_numero : Numéro du lot 3\n",
    "lot_3_surface_carrez : Surface Carrez du lot 3\n",
    "lot_4_numero : Numéro du lot 4\n",
    "lot_4_surface_carrez : Surface Carrez du lot 4\n",
    "lot_5_numero : Numéro du lot 5\n",
    "lot_5_surface_carrez : Surface Carrez du lot 5\n",
    "nombre_lots : Nombre de lots\n",
    "code_type_local : Code de type de local\n",
    "type_local : Libellé du type de local\n",
    "surface_reelle_bati : Surface réelle du bâti\n",
    "nombre_pieces_principales : Nombre de pièces principales\n",
    "code_nature_culture : Code de nature de culture\n",
    "nature_culture : Libellé de nature de culture\n",
    "code_nature_culture_speciale : Code de nature de culture spéciale\n",
    "nature_culture_speciale : Libellé de nature de culture spéciale\n",
    "surface_terrain : Surface du terrain\n",
    "longitude : Longitude du centre de la parcelle concernée (WGS-84)\n",
    "latitude : Latitude du centre de la parcelle concernée (WGS-84)    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are now ready to analyze data.\n",
    "\n",
    "Note that the following documentation may be a great help to assist you in this homework.\n",
    "\n",
    "https://sparkbyexamples.com/pyspark-tutorial/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open a connection to your Spark cluster :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N'oubliez pas de fermer la connexion à la fin du TP\n",
    "# spark.stop()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"spark://spark-master:7077\").appName(\"TP03\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check your connection :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://97d3001e8b6d:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://spark-master:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>TP03</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f0e96cc61d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Q1 - Open and infer the dataset into the mutationsDF dataframe ?\n",
    "    \n",
    "Note that the dataset schema should be automatically included into the dataframe.  \n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# ouverture du fichier csv en utilisant todayStr pour accéder au dossier du jour\n",
    "# l'inférence du schéma s'appuie sur une échantillonage et est par conséquent plus lourd\n",
    "# que l'ouverture simple du fichier \n",
    "\n",
    "pathFile = \"/data/permanent/rawdata/trade/2021-mutations-immobilieres.csv\"\n",
    "mutationsDF = spark.read.load(pathFile, format=\"csv\", sep=\",\", inferSchema=\"true\", header=\"true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Q2 - Display the data schema of mutationsDF dataframe ?  \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id_mutation: string (nullable = true)\n",
      " |-- date_mutation: string (nullable = true)\n",
      " |-- numero_disposition: integer (nullable = true)\n",
      " |-- nature_mutation: string (nullable = true)\n",
      " |-- valeur_fonciere: double (nullable = true)\n",
      " |-- adresse_numero: integer (nullable = true)\n",
      " |-- adresse_suffixe: string (nullable = true)\n",
      " |-- adresse_nom_voie: string (nullable = true)\n",
      " |-- adresse_code_voie: string (nullable = true)\n",
      " |-- code_postal: integer (nullable = true)\n",
      " |-- code_commune: string (nullable = true)\n",
      " |-- nom_commune: string (nullable = true)\n",
      " |-- code_departement: string (nullable = true)\n",
      " |-- ancien_code_commune: integer (nullable = true)\n",
      " |-- ancien_nom_commune: string (nullable = true)\n",
      " |-- id_parcelle: string (nullable = true)\n",
      " |-- ancien_id_parcelle: string (nullable = true)\n",
      " |-- numero_volume: string (nullable = true)\n",
      " |-- lot1_numero: string (nullable = true)\n",
      " |-- lot1_surface_carrez: double (nullable = true)\n",
      " |-- lot2_numero: string (nullable = true)\n",
      " |-- lot2_surface_carrez: double (nullable = true)\n",
      " |-- lot3_numero: string (nullable = true)\n",
      " |-- lot3_surface_carrez: double (nullable = true)\n",
      " |-- lot4_numero: string (nullable = true)\n",
      " |-- lot4_surface_carrez: double (nullable = true)\n",
      " |-- lot5_numero: integer (nullable = true)\n",
      " |-- lot5_surface_carrez: double (nullable = true)\n",
      " |-- nombre_lots: integer (nullable = true)\n",
      " |-- code_type_local: integer (nullable = true)\n",
      " |-- type_local: string (nullable = true)\n",
      " |-- surface_reelle_bati: integer (nullable = true)\n",
      " |-- nombre_pieces_principales: integer (nullable = true)\n",
      " |-- code_nature_culture: string (nullable = true)\n",
      " |-- nature_culture: string (nullable = true)\n",
      " |-- code_nature_culture_speciale: string (nullable = true)\n",
      " |-- nature_culture_speciale: string (nullable = true)\n",
      " |-- surface_terrain: integer (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mutationsDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Q3 - Display one row of your mutationsDF dataframe :\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+------------------+---------------+---------------+--------------+---------------+----------------+-----------------+-----------+------------+-------------+----------------+-------------------+------------------+--------------+------------------+-------------+-----------+-------------------+-----------+-------------------+-----------+-------------------+-----------+-------------------+-----------+-------------------+-----------+---------------+----------+-------------------+-------------------------+-------------------+--------------+----------------------------+-----------------------+---------------+---------+--------+\n",
      "|id_mutation|date_mutation|numero_disposition|nature_mutation|valeur_fonciere|adresse_numero|adresse_suffixe|adresse_nom_voie|adresse_code_voie|code_postal|code_commune|  nom_commune|code_departement|ancien_code_commune|ancien_nom_commune|   id_parcelle|ancien_id_parcelle|numero_volume|lot1_numero|lot1_surface_carrez|lot2_numero|lot2_surface_carrez|lot3_numero|lot3_surface_carrez|lot4_numero|lot4_surface_carrez|lot5_numero|lot5_surface_carrez|nombre_lots|code_type_local|type_local|surface_reelle_bati|nombre_pieces_principales|code_nature_culture|nature_culture|code_nature_culture_speciale|nature_culture_speciale|surface_terrain|longitude|latitude|\n",
      "+-----------+-------------+------------------+---------------+---------------+--------------+---------------+----------------+-----------------+-----------+------------+-------------+----------------+-------------------+------------------+--------------+------------------+-------------+-----------+-------------------+-----------+-------------------+-----------+-------------------+-----------+-------------------+-----------+-------------------+-----------+---------------+----------+-------------------+-------------------------+-------------------+--------------+----------------------------+-----------------------+---------------+---------+--------+\n",
      "|     2021-1|   2021-01-05|                 1|          Vente|       185000.0|          5080|           null|  CHE DE VOGELAS|             0471|       1370|       01426|Val-Revermont|              01|               null|              null|01426312ZC0122|              null|         null|       null|               null|       null|               null|       null|               null|       null|               null|       null|               null|          0|              1|    Maison|                 97|                        5|                  S|          sols|                        null|                   null|           2410| 5.386094|46.32714|\n",
      "+-----------+-------------+------------------+---------------+---------------+--------------+---------------+----------------+-----------------+-----------+------------+-------------+----------------+-------------------+------------------+--------------+------------------+-------------+-----------+-------------------+-----------+-------------------+-----------+-------------------+-----------+-------------------+-----------+-------------------+-----------+---------------+----------+-------------------+-------------------------+-------------------+--------------+----------------------------+-----------------------+---------------+---------+--------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# On affiche les 10 premières lignes tel qu'elles sont enregistrées dans le fichier\n",
    "mutationsDF.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Q4 - Create from mutationsDF dataframe a new Dataframe CleanMutationDF which matches the following constraints : \n",
    "* type_local is not null\n",
    "* type_local is 'Maison' or 'Appartement'\n",
    "* only the following attributes should be selected : id_mutation , nature_mutation, type_local , date_mutation , valeur_fonciere\n",
    "\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CleanMutationDF = mutationsDF.filter(\"type_local is not null AND ( type_local = 'Appartement' OR  type_local = 'Maison')\").select(\"id_mutation\",\"nature_mutation\",\"type_local\",\"date_mutation\",\"valeur_fonciere\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+-----------+-------------+---------------+\n",
      "|id_mutation|nature_mutation| type_local|date_mutation|valeur_fonciere|\n",
      "+-----------+---------------+-----------+-------------+---------------+\n",
      "|     2021-1|          Vente|     Maison|   2021-01-05|       185000.0|\n",
      "|     2021-3|          Vente|     Maison|   2021-01-04|       204332.0|\n",
      "|     2021-4|          Vente|     Maison|   2021-01-06|       320000.0|\n",
      "|     2021-6|          Vente|Appartement|   2021-01-04|       176000.0|\n",
      "|     2021-9|          Vente|     Maison|   2021-01-04|       226700.0|\n",
      "+-----------+---------------+-----------+-------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "CleanMutationDF.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Q5 - Save your CleanMutationDF dataframe into a parquet file ( /dataspark/mutations-immobilieres.parquet ) ?\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "CleanMutationDF.write.parquet('/data/permanent/processeddata/parquet/mutations-immobilieres.parquet') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need to remove the parquet file you can run the following cell :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /dataspark/mutations-immobilieres.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Q6 - Load  the parquet file ('/dataspark/mutations-immobilieres.parquet') into a mutationsPDF dataframe  ?</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chargement des données dans un dataframe \n",
    "\n",
    "mutationsPDF = spark.read.parquet('/data/permanent/processeddata/parquet/mutations-immobilieres.parquet') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.printSchema of DataFrame[id_mutation: string, nature_mutation: string, type_local: string, date_mutation: string, valeur_fonciere: double]>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutationsPDF.printSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Q7 - How many rows do you have in mutationsPDF ?</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1109023"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutationsPDF.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    " Please note that there may be several rows for the same transaction. All the rows part of a single transaction have the same identifier (i.e. the same value) in the id_mutation column. For instance, there are two rows with the value 2021-887 in the id_mutation column.\n",
    "</div>\n",
    "\n",
    "<font color='red'>Q8 - Select all rows concerning the id_mutation 2021-15481 into the singleTrDF dataframe :\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "singleTrDF = mutationsPDF.filter(mutationsPDF.id_mutation == '2021-15481')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+----------+-------------+---------------+\n",
      "|id_mutation|nature_mutation|type_local|date_mutation|valeur_fonciere|\n",
      "+-----------+---------------+----------+-------------+---------------+\n",
      "| 2021-15481|          Vente|    Maison|   2021-06-01|        88340.0|\n",
      "+-----------+---------------+----------+-------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "singleTrDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<font color='red'>Q9 - The singleTrDF contains 3 lines for the same transaction. How could you filtered out duplicated rows ? \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+----------+-------------+---------------+\n",
      "|id_mutation|nature_mutation|type_local|date_mutation|valeur_fonciere|\n",
      "+-----------+---------------+----------+-------------+---------------+\n",
      "| 2021-15481|          Vente|    Maison|   2021-01-13|       900000.0|\n",
      "+-----------+---------------+----------+-------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "singleTrDF.distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Q10 -  From mutationsPDF dataframe, create a new dataframe mutationDistinctPDF matching the following constraints :\n",
    "* no duplicated rows\n",
    "* selecting only nature_mutation = 'Vente'\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutationDistinctPDF = mutationsPDF.filter(\"nature_mutation = 'Vente'\").distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+----------+-------------+---------------+\n",
      "|id_mutation|nature_mutation|type_local|date_mutation|valeur_fonciere|\n",
      "+-----------+---------------+----------+-------------+---------------+\n",
      "|   2021-360|          Vente|    Maison|   2021-02-05|       285000.0|\n",
      "|   2021-980|          Vente|    Maison|   2021-03-31|        56000.0|\n",
      "|  2021-1139|          Vente|    Maison|   2021-04-02|       120000.0|\n",
      "|  2021-1239|          Vente|    Maison|   2021-04-12|       434020.0|\n",
      "|  2021-1719|          Vente|    Maison|   2021-01-29|       358000.0|\n",
      "+-----------+---------------+----------+-------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mutationDistinctPDF.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Q11 -  From mutationDistinctPDF dataframe, compare the sales amount (valeur_fonciere) between 'Maison' (House) and 'Appartment' by month\n",
    "</font>\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "Note that you can use the month function included into the pyspark.sql.functions to extract the month value from a date.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "341176"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import month\n",
    "\n",
    "\n",
    "#Some valeur_fonciere or date_mutation can be null\n",
    "# so we can drop Rows with NULL Values on Selected Columns\n",
    "CleanSales = mutationDistinctPDF.na.drop(subset=[\"valeur_fonciere\",\"date_mutation\"])\n",
    "\n",
    "CleanSales.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+-----------------------------+\n",
      "|mois|type_local |sum(valeur_fonciere AS total)|\n",
      "+----+-----------+-----------------------------+\n",
      "|3   |Maison     |8.66192723233E9              |\n",
      "|5   |Maison     |7.15093441882E9              |\n",
      "|6   |Maison     |8.138101043709997E9          |\n",
      "|3   |Appartement|6.707402151400001E9          |\n",
      "|2   |Maison     |7.677523595549999E9          |\n",
      "|6   |Appartement|6.682449287090001E9          |\n",
      "|1   |Appartement|6.04043523954E9              |\n",
      "|2   |Appartement|5.566652159379999E9          |\n",
      "|5   |Appartement|5.737454823870001E9          |\n",
      "|4   |Appartement|6.111317165559999E9          |\n",
      "|4   |Maison     |8.158892162630002E9          |\n",
      "|1   |Maison     |8.317504558539999E9          |\n",
      "+----+-----------+-----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as f \n",
    "# we are now ready to compute the sum\n",
    "\n",
    "Sales = CleanSales.withColumn('mois', month(\"date_mutation\")).groupBy(\"mois\",\"type_local\") \\\n",
    "    .agg( f.sum(mutationDistinctPDF['valeur_fonciere'].alias(\"total\"))) \n",
    "\n",
    "Sales.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Q12 - Determine the month where sales amount is highest for 'Maison' and 'Appartement' ?\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+-------------------------+\n",
      "|type_local|mois|max(sum(valeur_fonciere))|\n",
      "+----------+----+-------------------------+\n",
      "|    Maison|   3|          8.66192723233E9|\n",
      "+----------+----+-------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Sales.filter(\"type_local = 'Maison'\").groupBy('type_local','mois').max(\"sum(valeur_fonciere)\").show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+-------------------------+\n",
      "| type_local|mois|max(sum(valeur_fonciere))|\n",
      "+-----------+----+-------------------------+\n",
      "|Appartement|   3|      6.707402151400001E9|\n",
      "+-----------+----+-------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Sales.filter(\"type_local = 'Appartement'\").groupBy('type_local','mois').max(\"sum(valeur_fonciere)\").show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you will handle the dataset using the SQL language.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Q13 - From the mutationDistinctPDF dataframe, create a view mutationSalesV ?</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# création de la vue 'mutationV' \n",
    "mutationDistinctPDF.createOrReplaceTempView(\"mutationSalesV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Q14 -  From the mutationSalesV view, compare the sales amount (valeur_fonciere) between 'Maison' (House) and 'Appartment' by month using SQL ?\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+--------------------+\n",
      "|month(date_mutation)|type_local |sum(valeur_fonciere)|\n",
      "+--------------------+-----------+--------------------+\n",
      "|3                   |Maison     |8.66192723233E9     |\n",
      "|5                   |Maison     |7.150934418820001E9 |\n",
      "|6                   |Maison     |8.138101043709997E9 |\n",
      "|3                   |Appartement|6.707402151400002E9 |\n",
      "|2                   |Maison     |7.677523595550001E9 |\n",
      "|6                   |Appartement|6.68244928709E9     |\n",
      "|1                   |Appartement|6.040435239540002E9 |\n",
      "|2                   |Appartement|5.566652159379999E9 |\n",
      "|5                   |Appartement|5.737454823870001E9 |\n",
      "|4                   |Appartement|6.11131716556E9     |\n",
      "|4                   |Maison     |8.158892162629999E9 |\n",
      "|1                   |Maison     |8.317504558539999E9 |\n",
      "+--------------------+-----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select month(date_mutation), type_local, sum(valeur_fonciere) from mutationSalesV  group by month(date_mutation), type_local order by month\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Close your Spark connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
