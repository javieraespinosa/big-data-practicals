{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction à SPARK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Présentation\n",
    "\n",
    "\n",
    "SPARK est un framework qui peut fonctionner de manière autonome ou être intégré à un cluster hadoop.\n",
    "Ce qui est intéressant avec SPARK, le développeur peut se concentrer sur son application métier sans se soucier des problématiques lié aux traitements distribués.\n",
    "\n",
    "Vous pouvez voir  SPARK comme une machine virtuelle composée de nombreuses ressources informatiques (CPU et RAM) qui exécute votre code.\n",
    "\n",
    "Pour rendre transparente la logique cachée derrière l'informatique distribuée, SPARK utilise le concept de Resilient Distributed Dataset (RDD).\n",
    "Un RDD est une API qui vous permet d'interagir avec vos données de manière unifiée et fournit de nombreuses fonctions pour faciliter la programmation.\n",
    "\n",
    "Nous pouvons diviser l'API RDD en deux parties:\n",
    "* Transformation:\n",
    "Comme son nom l'indique, une transformation est un moyen de transformer vos données en quelque chose d'autre. Par exemple, si vous devez filtrer des données, nous transformons la source de données en filtrant les données, ce qui donnera un nouveau RDD.\n",
    "Notez qu'une source de données (RDD) est immuable, vous ne pouvez donc pas en modifier le contenu. Pour modifier un RDD, l'astuce est d'appliquer vos modifications via des transformations qui seront contenues dans un nouveau RDD que vous pourrez sauvegarder.\n",
    "La liste des transformations possibles est disponible sur le site d'apache Spark :\n",
    "https://spark.apache.org/docs/latest/rdd-programming-guide.html#transformations\n",
    "\n",
    "* Action :\n",
    "SPARK est fénéant/lazyness, cela signifie que SPARK ne fait rien tant que le programme n’exécute pas une  action. Par exemple, la fonction count()  est une action qui comptabilie le nombre de n-uplets dans le RDD.\n",
    "Vous trouverez l'ensemble des actions possibles sur le site de Spark :\n",
    "https://spark.apache.org/docs/latest/rdd-programming-guide.html#actions\n",
    "\n",
    "Ce laboratoire vous présentera comment développer une application SPARK avec Python.\n",
    "La librairie python pour Spark est détaillée ici :\n",
    "https://spark.apache.org/docs/2.1.0/api/python/pyspark.html#pyspark.RDD\n",
    "\n",
    "Bien entendu, vous pouvez consulter le site Web de SPARK pour obtenir plus de détails: https://spark.apache.org/docs/latest/index.html\n",
    "\n",
    "\n",
    "Alors, commençons maintenant quelques exemples pour devenir familier avec SPARK\n",
    "\n",
    "Dans ce TP, nous explorerons les transformations et actions courantes fournies par Spark:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2 Pré-requis\n",
    "\n",
    "### Démarrer Spark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour démarrer votre cluster Spark, si cela n'a pas déjà été fait, vous devrez ouvrir un terminal puis exécuter la commande suivante :"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "docker start smaster sworker1 sworker2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérifiez que les containers smaster, sworker1 et sworker2 sont démarrés :"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "docker ps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connexion à Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons à présent établir une connexion avec notre cluster Spark.\n",
    "\n",
    "Le notebook sera le driver lequel soumettra notre programme sur notre cluster Spark.\n",
    "\n",
    "Nous utiliserons ce qu'on appelle un sparkContext pour identifier l'emplacement du cluster Spark.\n",
    "\n",
    "Pour utiliser l'API RDD Spark, on crée un objet de connexion au cluster Spark :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Attention le driver ne peut instancier qu'un seul SparkContext\n",
    "# Si vous exécuter plusieurs fois cette cellule vous obtiendrez une erreur:\n",
    "# Cannot run multiple SparkContexts at once;\n",
    "# Pensez bien à fermer le Sparkcontext à la fin de chaque TP avec la commande sc.stop()\n",
    "\n",
    "from pyspark import SparkContext\n",
    "\n",
    "sc = SparkContext(\"spark://smaster:7077\", \"TPSPARK\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour vérifier le point d'accés au cluster : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://bc5d4b6a89c6:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://smaster:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>TPSPARK</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=spark://smaster:7077 appName=TPSPARK>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Débuter avec Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour faciliter la prise en main de Spark, nous allons travailler avec de petits jeux de données.\n",
    "Nous utiliserons des RDD contenant de 1 à 5 valeurs numériques mais il faut considérer que chaque valeur peut être une ligne d'un fichier.\n",
    "\n",
    "### Collect / take / first / last\n",
    "\n",
    "Renvoye tous / certains / le premier  éléments du RDD au driver dans une simple liste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.rdd.RDD'>\n",
      "Collecte tous les éléments [1, 2, 3, 4, 5]\n",
      "Collecte une partie des éléments [1, 2, 3]\n",
      "Collecte le 1er élément 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nums= sc.parallelize([1,2,3,4,5])\n",
    "print(type(nums))\n",
    "\n",
    "print( 'Collecte tous les éléments', nums.collect())\n",
    "print( 'Collecte une partie des éléments', nums.take(3))\n",
    "print( 'Collecte le 1er élément', nums.first())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Les Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode map prend une fonction en entrée et l'applique à chaque élément du RDD source pour créer un nouveau RDD.\n",
    "La fonction d'entrée doit prendre un seul paramètre d'entrée et renvoyer une valeur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type de nums :  <class 'pyspark.rdd.RDD'>\n",
      "plusOneRDD is new RDD\n",
      "Type de pluOneRDD :  <class 'pyspark.rdd.PipelinedRDD'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2, 3, 4]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nums= sc.parallelize([1,2,3])\n",
    "\n",
    "print(\"Type de nums : \", type(nums))\n",
    "pluOneRDD = nums.map(lambda x : x+1)\n",
    "print(\"plusOneRDD is new RDD\")\n",
    "print(\"Type de pluOneRDD : \", type(pluOneRDD))\n",
    "pluOneRDD.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une autre manière d'écrire ce programme :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "map with lambda function\n",
      "[1, 1, 9]\n"
     ]
    }
   ],
   "source": [
    "nums= sc.parallelize([1,2,3])\n",
    "\n",
    "def plus1(x):\n",
    "    if( x > 2 ):\n",
    "        s = x*x\n",
    "    else:\n",
    "        s = 1\n",
    "    return s\n",
    "\n",
    "# on  appelle la fonction plus1 directement dans la phase map\n",
    "pluOneRDD = nums.map(lambda x : plus1(x))\n",
    "\n",
    "print(\"map with lambda function\")\n",
    "print(pluOneRDD.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tranformer la collection suivante [“John”, “Fred”, “Anna”, “James”] afin de retourner le nombre de caractères de chaque élément :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 4, 4, 5]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = sc.parallelize([\"John\", \"Fred\", \"Anna\", \"James\"])\n",
    "# Complétez le code\n",
    "y = x.map( lambda x : len(x))\n",
    "y.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FILTER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le filtre prend une fonction booléenne en entrée et l'applique à chaque élément du RDD source pour créer un nouveau RDD.\n",
    "Une fonction booléenne prend une entrée et renvoie true ou false.\n",
    "La méthode de filtrage renvoie un nouveau RDD formé en sélectionnant uniquement les éléments pour lesquels la fonction booléenne en entrée a renvoyé la valeur true.\n",
    "Ainsi, le nouveau RDD contient un sous-ensemble des éléments du RDD d'origine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nums= sc.parallelize([1,2,3])\n",
    "myFilteredRDD = nums.filter(lambda x : x > 1)\n",
    "myFilteredRDD.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changez la collection pour ne conserver que les nombres pairs et calculez le carré:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nums= sc.parallelize([1,2,3])\n",
    "# Complétez le code\n",
    "even= nums.filter(lambda x : x % 2 == 0).map(lambda x: x*x)\n",
    "even.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FLATMAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FlatMap prend une fonction d'entrée, qui renvoie une séquence pour chaque élément d'entrée qui lui est transmis.\n",
    "La méthode flatMap renvoie un nouveau RDD formé en aplatissant cette collection de séquences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Display MapRDD :\n",
      "[(1, 1, 1), (2, 4, 8), (3, 9, 27)]\n",
      "\n",
      "Display flatMapRDD :\n",
      "[1, 1, 1, 2, 4, 8, 3, 9, 27]\n"
     ]
    }
   ],
   "source": [
    "nums= sc.parallelize([1,2,3])\n",
    "mapRDD = nums.map(lambda x : (x,x*x,x*x*x))\n",
    "flatMapRDD = mapRDD.flatMap(lambda x : x )\n",
    "print(\"Display MapRDD :\")\n",
    "print(mapRDD.collect())\n",
    "\n",
    "print(\"\\nDisplay flatMapRDD :\")\n",
    "print(flatMapRDD.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comptez le nombre de mots contenu dans l'ensemble des lignes faisant référence au \"spam\":\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indice: vous utiliserez la fonction flatMap\n",
    "data = sc.parallelize([\"Spark c'est bien\",\"il peut nous aider à trouver les spams\",\"spam viagra.com\"])\n",
    "mapRDD = data.filter(lambda x: \"spam\" in x).flatMap(lambda x : x.split())\n",
    "mapRDD.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Union prend un RDD en entrée et retourne un nouveau RDD contenant l'union des éléments dans le RDD source et le RDD qui lui est transmis en tant qu'entrée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2], 3, 1, 2, 3]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = sc.parallelize([[1,2],3])\n",
    "y = sc.parallelize([1,2,3])\n",
    "z = x.union(y)\n",
    "z.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INTERSECTION "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode intersection prend un RDD en entrée et retourne un nouveau RDD contenant l'intersection des éléments du RDD source et du RDD qui lui est transmis en tant qu'entrée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = sc.parallelize([1,2,3])\n",
    "y = sc.parallelize([4,6,3])\n",
    "z = x.intersection(y)\n",
    "z.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## La transformation subtract "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode subtract prend un RDD en entrée et retourne un nouveau RDD contenant des éléments dans le RDD source mais pas dans le RDD en entrée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = sc.parallelize([1,2,3])\n",
    "y = sc.parallelize([4,6,3])\n",
    "z = x.subtract(y)\n",
    "z.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## La transformation Distinct "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode distincte d'un RDD renvoie un nouveau RDD contenant les éléments distincts dans le RDD source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4, 1, 3, 5]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = sc.parallelize([1,2,3,4,5,3,2,4])\n",
    "y = x.distinct()\n",
    "y.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## La transformation Join "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "La méthode de \"join\" prend un RDD de paires clé-valeur en entrée et effectue une jointure interne sur les RDD source et en entrée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Google', 532), ('Twitter', 36), ('Apple', 127)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = sc.parallelize([(\"TWTR\", \"Twitter\"), (\"GOOG\", \"Google\"), (\"AAPL\", \"Apple\")])\n",
    "y = sc.parallelize([(\"TWTR\", 36), (\"GOOG\", 532), (\"AAPL\", 127)])\n",
    "z = x.join(y).map(lambda x : x[1])\n",
    "z.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## La transformation KeyBy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créez un RDD Pair,  formant une paire pour chaque article du RDD original.\n",
    "La clé de la paire est calculée à partir de la valeur via une fonction fournie par l'utilisateur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0), (1, 1), (4, 2), (9, 3), (16, 4)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = sc.parallelize(range(0,5)).keyBy(lambda x: x*x)\n",
    "x.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 4\n",
    "\n",
    "\n",
    "Créez un RDD à partir de cette liste, puis utilisez .keyBy pour créer une paire RDD avec: \n",
    "['New York, NY', 'Philadelphia, PA', 'Denver, CO', 'San Francisco, CA'])\n",
    "\n",
    "Résultat :\n",
    "[('New York', ' NY'), ('Philadelphia', ' PA'), ('Denver', ' CO'), ('San Francisco', ' CA')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('New York', ' NY'),\n",
       " ('Philadelphia', ' PA'),\n",
       " ('Denver', ' CO'),\n",
       " ('San Francisco', ' CA')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = sc.parallelize(['New York, NY', 'Philadelphia, PA', 'Denver, CO', 'San Francisco, CA'])\n",
    "\n",
    "# Complétez le code\n",
    "y.keyBy(lambda x : x.split(\",\")[0]).map(lambda a : (a[0],a[1].split(\",\")[1])).collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation leftOuterJoin / rightOuterJoin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effectue une jointure externe gauche / droite à l'aide de deux RDD clé-valeur. Veuillez noter que les touches doivent être généralement comparables pour que cela fonctionne correctement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('b', (2, 5)), ('c', (2, None)), ('a', (1, 4)), ('a', (1, 3))]\n"
     ]
    }
   ],
   "source": [
    "x = sc.parallelize([(\"a\", 1), (\"b\", 2), (\"c\", 2)])\n",
    "y = sc.parallelize([(\"a\", 3), (\"a\", 4), (\"b\", 5)] )\n",
    "z = x.leftOuterJoin(y)\n",
    "print(z.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Créer une paire RDD renvoyant tous les mots par longueur pour les deux listes:\n",
    "\n",
    "list1 = [\"dog\",\"cat\",\"gnu\",\"salmon\",\"rabbit\",\"turkey\",\"wolf\",\"bear\",\"bee\"]\n",
    "list2 = [“dog”, “salmon”, “salmon”, “rat”, “elephant”]\n",
    "\n",
    "Notez que le programme devra renvoyer au minimum tous les éléments de la list1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, ('wolf', None)),\n",
       " (4, ('bear', None)),\n",
       " (6, ('salmon', 'salmon')),\n",
       " (6, ('salmon', 'salmon')),\n",
       " (6, ('rabbit', 'salmon')),\n",
       " (6, ('rabbit', 'salmon')),\n",
       " (6, ('turkey', 'salmon')),\n",
       " (6, ('turkey', 'salmon')),\n",
       " (3, ('dog', 'dog')),\n",
       " (3, ('dog', 'rat')),\n",
       " (3, ('cat', 'dog')),\n",
       " (3, ('cat', 'rat')),\n",
       " (3, ('gnu', 'dog')),\n",
       " (3, ('gnu', 'rat')),\n",
       " (3, ('bee', 'dog')),\n",
       " (3, ('bee', 'rat'))]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list2 = sc.parallelize(['dog', 'salmon', 'salmon', 'rat', 'elephant'])\n",
    "list1 = sc.parallelize(['dog','cat','gnu','salmon','rabbit','turkey','wolf','bear','bee'])\n",
    "\n",
    "# Complétez le code\n",
    "z = list1.keyBy(lambda x : len(x))\n",
    "v = list2.keyBy(lambda x : len(x))\n",
    "w = z.leftOuterJoin(v)\n",
    "w.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## La transformation PartitionBy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renvoie un nouveau RDD avec le nombre spécifié de partitions, en plaçant les éléments d'origine dans la partition renvoyée par un partitionneur fourni par l'utilisateur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 partitions :  [[('J', 'John'), ('J', 'James')], [('F', 'Fred'), ('A', 'Anna')]]\n",
      "3 partitions :  [[('J', 'James'), ('J', 'John')], [('A', 'Anna')], [('F', 'Fred')]]\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize([('J', \"James\"), ('F', \"Fred\"), ('A', \"Anna\"), ('J', \"John\")])\n",
    "\n",
    "rdd1 = rdd.partitionBy(2)\n",
    "rdd2 = rdd.partitionBy(3)\n",
    "\n",
    "print(\"2 partitions : \",rdd1.glom().collect())\n",
    "print(\"3 partitions : \",rdd2.glom().collect())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## La transformation Zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renvoye un nouveau fichier RDD contenant des paires dont la clé est l’élément du fichier original, et dont la valeur correspond à l’élément correspondant de cet élément (même partition, même index) dans un deuxième fichier RDD.\n",
    "\n",
    "![title](http://i.imgur.com/5J0lg6g.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1000), (1, 1001), (2, 1002), (3, 1003), (4, 1004)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = sc.parallelize(range(0,5))\n",
    "y = sc.parallelize(range(1000, 1005))\n",
    "x.zip(y).collect()\n",
    "[(0, 1000), (1, 1001), (2, 1002), (3, 1003), (4, 1004)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Les actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les actions calculent un résultat (par exemple, des données numériques ou créer une structure de données non RDD) ou produire un effet secondaire, tel que l'écriture d'une sortie sur un disque.\n",
    "___________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L'action Reduce "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comptez le nombre de mots pour cette liste avec les fonctions map et reduce:\n",
    "\n",
    "[‘Spark s est vraiement facile’,‘Qu en pensez vous ?’]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import add\n",
    "x = sc.parallelize(['Spark s est vraiement facile','Qu en pensez vous ?'])\n",
    "y = x.map(lambda x : x.split(' ')).flatMap(lambda x : x).map(lambda x : 1)\n",
    "y.reduce(add)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les actions : Count, Max, Min, Sum, Mean, Variance, Stdev, stats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count 10\n",
      "max 9\n",
      "min 0\n",
      "sum 45\n",
      "mean 4.5\n",
      "variance 8.25\n",
      "stdev 2.8722813232690143\n",
      "stat (count: 10, mean: 4.5, stdev: 2.8722813232690143, max: 9, min: 0)\n"
     ]
    }
   ],
   "source": [
    "x = sc.parallelize(range(10))\n",
    "\n",
    "print(\"count\",x.count())\n",
    "print(\"max\",x.max())\n",
    "print(\"min\",x.min())\n",
    "print(\"sum\",x.sum())\n",
    "print(\"mean\",x.mean())\n",
    "print(\"variance\",x.variance())\n",
    "print(\"stdev\",x.stdev())\n",
    "print(\"stat\", x.stats())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L'action CountByKey "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CountByKey : Retourne une liste des clés et compte leurs occurrences dans le RDD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'J': 2, 'F': 1, 'A': 1})\n"
     ]
    }
   ],
   "source": [
    "x = sc.parallelize([('J', \"James\"), ('F', \"Fred\"), ('A', \"Anna\"), ('J', \"John\")])\n",
    "y = x.countByKey()\n",
    "\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReduceByKey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regroupe tous les éléments du RDD en appliquant une fonction utilisateur par paire aux éléments et aux résultats partiels et renvoyez un résultat au pilote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 100), (1, 50)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import add\n",
    "z = sc.parallelize([(1,20),(1,30),(3,60),(3,20),(3,20)])\n",
    "\n",
    "result = z.reduceByKey(add)\n",
    "result.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comptez le nombre de mots pour cette liste avec la fonction map et reduce :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import add\n",
    "x = sc.parallelize(['Spark s est vraiement facile','Qu en pensez vous ?'])\n",
    "# Complétez le code\n",
    "y = x.map(lambda x : x.split(' ')).flatMap(lambda x : x).map(lambda x : 1)\n",
    "y.reduce(add)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez à présent fermer le SparkContext."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
